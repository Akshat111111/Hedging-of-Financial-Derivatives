{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**genetic algorithm on Credit Risk Modeling Using Genetic Algorithms with DEAP libarary**"
      ],
      "metadata": {
        "id": "vuWcTrwFubpE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NICtjZsqL96P",
        "outputId": "19e627af-7861-4674-87d8-75e004c78df5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.25.2)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install deap\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from deap import base, creator, tools, algorithms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "UenusVy6u4fO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "credit_data = pd.read_csv('/content/credit_data.csv')"
      ],
      "metadata": {
        "id": "hvLY9zihu8wI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and target\n",
        "X = credit_data.drop(columns=['CustomerID', 'Default'])\n",
        "y = credit_data['Default']\n"
      ],
      "metadata": {
        "id": "nXyPZiJsu_G-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "szazMpEUvCYe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate(individual):\n",
        "    n_estimators = int(individual[0])\n",
        "    max_depth = int(individual[1])\n",
        "    min_samples_split = int(individual[2])\n",
        "    min_samples_leaf = int(individual[3])\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    return accuracy,\n",
        "\n",
        "# Setup DEAP\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_int\", np.random.randint, 10, 200)\n",
        "toolbox.register(\"attr_depth\", np.random.randint, 1, 50)\n",
        "toolbox.register(\"attr_samples_split\", np.random.randint, 2, 10)\n",
        "toolbox.register(\"attr_samples_leaf\", np.random.randint, 1, 10)\n",
        "\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_int, toolbox.attr_depth, toolbox.attr_samples_split, toolbox.attr_samples_leaf), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutUniformInt, low=[10, 1, 2, 1], up=[200, 50, 10, 10], indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "# Genetic Algorithm parameters\n",
        "population = toolbox.population(n=50)\n",
        "n_generations = 20\n",
        "crossover_prob = 0.7\n",
        "mutation_prob = 0.2\n",
        "\n",
        "# Run Genetic Algorithm\n",
        "for gen in range(n_generations):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=crossover_prob, mutpb=mutation_prob)\n",
        "    fits = list(map(toolbox.evaluate, offspring))\n",
        "\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    population = toolbox.select(offspring, k=len(population))\n",
        "\n",
        "    top_ind = tools.selBest(population, k=1)[0]\n",
        "    print(f\"Generation {gen}: Best Accuracy = {top_ind.fitness.values[0]}\")\n",
        "\n",
        "# Best individual\n",
        "best_ind = tools.selBest(population, k=1)[0]\n",
        "print(\"Best individual is:\", best_ind)\n",
        "print(\"with fitness:\", best_ind.fitness.values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEQr-fSDt9VQ",
        "outputId": "c31e77a8-9d32-4d55-87b9-3733683e21a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 0: Best Accuracy = 0.535\n",
            "Generation 1: Best Accuracy = 0.545\n",
            "Generation 2: Best Accuracy = 0.545\n",
            "Generation 3: Best Accuracy = 0.545\n",
            "Generation 4: Best Accuracy = 0.545\n",
            "Generation 5: Best Accuracy = 0.545\n",
            "Generation 6: Best Accuracy = 0.545\n",
            "Generation 7: Best Accuracy = 0.545\n",
            "Generation 8: Best Accuracy = 0.545\n",
            "Generation 9: Best Accuracy = 0.545\n",
            "Generation 10: Best Accuracy = 0.545\n",
            "Generation 11: Best Accuracy = 0.545\n",
            "Generation 12: Best Accuracy = 0.545\n",
            "Generation 13: Best Accuracy = 0.545\n",
            "Generation 14: Best Accuracy = 0.545\n",
            "Generation 15: Best Accuracy = 0.545\n",
            "Generation 16: Best Accuracy = 0.545\n",
            "Generation 17: Best Accuracy = 0.545\n",
            "Generation 18: Best Accuracy = 0.545\n",
            "Generation 19: Best Accuracy = 0.545\n",
            "Best individual is: [179, 18, 3, 4]\n",
            "with fitness: (0.545,)\n"
          ]
        }
      ]
    }
  ]
}